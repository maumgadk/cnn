#-*- encoding: utf-8 -*-
import math
import tensorflow as tf
import numpy as np
from PIL import Image
import h5py
import datetime

class cnn:
    """
    CNN layer parameter 
    """

    def __init__(self,num_w_fltr, num_b_fltr, weight, bias):
        self.num_w_fltr = num_w_fltr # (channel, filter)
        self.num_b_fltr = num_b_fltr # (filter, 1)
        self.weight = weight
        self.bias = bias

class nn_img:
    """
    Images for training or testing
    images: imasges for neural network input
    labels: images for reference
    """

    def __init__(self, images, labels):
        self._size = len(images)
        self.images = images
        self.labels = labels
        self.batch_idx = 0

    def reset_batch_index(self, rd_idx=0):
        self.batch_idx = rd_idx

    def next_batch(self, batch_size):
        """
        function for mini batch training
        """
        if self.batch_idx == self._size:
            self.batch_idx = 0
        prev_idx = self.batch_idx
        self.batch_idx = min(self._size, self.batch_idx + batch_size)

        return (self.images[prev_idx : self.batch_idx ], 
                self.labels[prev_idx : self.batch_idx ])


class imgData:
    """
    Image Data set : Generated by SCRNN, please refer generate_test.m

    """
    def __init__(self, test_h5, train_h5):
        self.test = nn_img(test_h5['data'], test_h5['label'])
        self.train = nn_img(train_h5['data'], train_h5['label'])

def setCNNParameter():
    """ Set channel number and filter number of each cnn layer for training"""

    num_layer = 20
    NNlayer = []
    for i in range(num_layer):
        if i ==0:
            layer = cnn((1,64),(64,1), None, None)
        elif i== (num_layer -1):
            #(c,f,b,1)
            layer = cnn((64,1),(1,1), None, None)
        else:
            layer = cnn((64,64),(64,1), None, None)
        NNlayer.append(layer)

    return NNlayer


def genCNNParameter(dat):
    """ read CNN parameter from model.txt"""

    NNlayer = []
    for i in range(len(dat)):
        dat2 = dat[i].split(', ')
        npdat2 = np.array(dat2[:-1], np.float16)

        #fn1: number of channel
        #fn2: number of filter
        #
        head = 4
        fw, fh, fn1, fn2 = npdat2[:head].astype("int32")

        if i == (len(dat) - 1):
            head = 3
            fw, fh, fn1 = npdat2[:head].astype("int32")
            fn2 = 1

        dsize = fw * fh * fn1 * fn2
        weight = npdat2[head:dsize + head]
        bias1, bias2 = dat2[head + dsize:dsize + head + 2]
        bias = npdat2[dsize + 2 + head:]

        weight =np.array(weight).reshape(fn1,fn2,fh,fw)
        weight = np.swapaxes(weight, 0,3)
        weight = np.swapaxes(weight, 1,2)

        layer = cnn((fn1, fn2), (bias1, bias2), weight, bias)

        NNlayer.append(layer)

    return NNlayer


def getYCbCr(fn):
    """ read image file (fn) and return numpy array of Y, Cb, Cr """

    im = Image.open(fn)
    im = im.convert('YCbCr')
    imYCbCr= np.array(im)
    imY= imYCbCr[:, :, 0]  # to make a separate copy as array is immutable
    imCb= imYCbCr[:, :, 1]  # to make a separate copy as array is immutable
    imCr= imYCbCr[:, :, 2]  # to make a separate copy as array is immutable


    return imY, imCb, imCr


def getBlur(img):
    """ return blured image using bicubic operation"""

    dim = img.shape
    half_dim = dim[0]//2, dim[1]//2
    im = Image.fromarray(img, mode='L')
    im = im.resize(half_dim, Image.BICUBIC)
    im = im.resize(dim, Image.BICUBIC)

    return np.array(im)


def blurAndNormalize(fn):
    """ blur and then normalize Y pixel value by 255"""

    Y, Cb, Cr = getYCbCr(fn)
    blurImg = getBlur(Y)

    return blurImg/255.


def testModel(NNlayer, imY, nLayer=20):
    """ function to test VDSR nn using pre-trained model parameter in model.txt which is obtained from VDSR github
    """

    dim=imY.shape
    features = tf.placeholder('float', [None, dim[0], dim[1]], name='Input')
    input_layer = tf.reshape(features, [-1, dim[0], dim[1] , 1])
    rawInput = tf.reshape(features, [-1, dim[0], dim[1], 1])

    w = dict()
    b = dict()

    for i, layer in enumerate(NNlayer[:nLayer]):
        nFilter = int(layer.num_w_fltr[1])
        nChannel = int(layer.num_w_fltr[0])
        nBias = int(layer.num_b_fltr[0])

        w[i] = tf.placeholder('float', [3, 3, nChannel, nFilter])
        b[i] = tf.placeholder('float', [nBias])


        x = tf.nn.conv2d(input_layer, filter=w[i], strides=[1, 1, 1, 1], padding='SAME', name="Conv" + str(i))
        conv = tf.nn.bias_add(x, b[i])

        if i < (len(NNlayer) - 1):
            conv = tf.nn.relu(conv)
        input_layer = conv

    result = conv + rawInput

    weight ={}
    bias = {}
    for i, layer in enumerate(NNlayer[:nLayer]):
        weight[i] = layer.weight.reshape(3,3,int(layer.num_w_fltr[0]), int(layer.num_w_fltr[1]))
        bias[i] = layer.bias.reshape(int(layer.num_b_fltr[0]))

    sess=tf.Session()
    tf.global_variables_initializer()

    fd = {}
    fd[features] = [imY]
    for i in range(len(NNlayer[:nLayer])):
        fd[w[i]] = weight[i]
        fd[b[i]] = bias[i]
    res = sess.run(result,feed_dict=fd)
    return res


def weight_variable(shape):
    """ Initialize neural network weights(Tensorflow variable) """
    initial = tf.truncated_normal(shape, stddev=0.1)
    return tf.Variable(initial)


def bias_variable(shape):
    """ Initialize neural network bias (Tensorflow variable) """
    initial = tf.constant(0.1, shape=shape)
    return tf.Variable(initial)


def restoreModel(session):
    """ restore Graph and model parameters"""
    """
    try:
        new_saver = tf.train.import_meta_graph('model.ckpt.meta')
    except IOError:
        new_saver = None

    if new_saver is not None:
        new_saver.restore(sess, tf.train.latest_checkpoint('./'))
    """
    saver = tf.train.Saver()

    try:
        saver.restore(session, './model.ckpt')

    except:
        pass
    
    return saver 


def initTraining(img_data):
    """Initialize  """
    nEpoch = 10 
    batch_size = 50
    training_data_size = len(img_data.train.images)
    #training_data_size = 3000 
    ##step per Epoch = 24930, (batch_size = 50, training_data_size = len(img_data.train.images)

    try:
        f = open('iter.txt', 'r')
        rd_idxs = f.readlines()
        f.close()

        if len(rd_idxs) == 0: rd_idx = 0
        else: rd_idx = int(rd_idxs[-1])

        if rd_idx >= training_data_size: rd_idx = 0

    except IOError:
        rd_idx = 0

    print ('rd_idx: %d'%rd_idx)


    return nEpoch, batch_size, training_data_size, rd_idx

def trainModel(NNlayer, img_data, img_shape, isTest=False):
    """
    :param NNlayer: data structure for convolutional neural network
    :param img_data: image structure for training and test
    :param img_shape: dimension of image (height, width)
    :param isTest: if True: train, else reconstruct img_data
    :return: if isTest: reconstructed image, else PSNR of training result
    """
    nLayer = len(NNlayer) #number of layer

    dim=img_shape
    _size = dim[0]*dim[1]
    features = tf.placeholder('float', [None, 1, dim[0], dim[1]], name='TrInput')
    input_layer = tf.reshape(features, [ -1, dim[0], dim[1] , 1])
    rawInput = tf.reshape(features, [ -1, dim[0], dim[1], 1])

    ref_img = tf.placeholder('float', [None, 1, dim[0], dim[1]], name='result')
    y_ = tf.reshape(ref_img, [ -1, dim[0], dim[1] , 1])

    w = dict()
    b = dict()

    for i, layer in enumerate(NNlayer[:nLayer]):
        nChannel = int(layer.num_w_fltr[0])
        nFilter = int(layer.num_w_fltr[1])
        nBias = int(layer.num_b_fltr[0])
        
        w[i] = weight_variable([3, 3, nChannel, nFilter])
        b[i] = bias_variable([nBias])
        
        x = tf.nn.conv2d(input_layer, filter=w[i], 
            strides=[1, 1, 1, 1], padding='SAME', name="Conv" + str(i))
        conv = tf.nn.bias_add(x, b[i])
        
        if i < (len(NNlayer) - 1):
            conv = tf.nn.relu(conv)
        input_layer = conv
    
    result = conv + rawInput


    SSE_res = tf.reduce_sum(tf.square(tf.subtract( y_,  result)))


    global_step = tf.Variable(0, trainable=False)
    starter_learning_rate = 0.1
    learning_rate = tf.train.exponential_decay(starter_learning_rate, 
            global_step, 100000, 0.96, staircase=True)
    train_step = tf.train.AdamOptimizer(learning_rate).minimize(SSE_res) #1e-3

    #train_step = tf.train.AdamOptimizer(1e-2).minimize(SSE_res) #1e-3

    #sess=tf.Session(config=tf.ConfigProto(log_device_placement=True))
    sess=tf.Session()
    sess.run(tf.global_variables_initializer())

    #tf.add_to_collection('features', features)
    #tf.add_to_collection('ref_img', ref_img)
    #tf.add_to_collection('result', result)

    #Load variables saved

    saver = restoreModel(sess)

    if isTest:
        return sess.run(result, feed_dict={features: [img_data.test.images[0:1]], 
                                   ref_img: [img_data.test.images[0:1]] })

    nEpoch, batch_size, training_data_size, rd_idx = initTraining(img_data)
    PSNR = 0.

    logFile = open('psnr_log.txt', 'a')
    f = open('iter.txt', 'w')

    start_time = datetime.datetime.now()
    for niter in range(nEpoch):
        if niter >0: rd_idx = 0

        img_data.train.reset_batch_index(rd_idx)

        #for i in range(training_data_size//batch_size):
        i=0
        while( img_data.train.batch_idx <= training_data_size):
            batch = img_data.train.next_batch(batch_size)

            if i % batch_size == 0:
                sse = sess.run(SSE_res, feed_dict={features: batch[0], ref_img: batch[1]})
                PSNR = psnr(sse/_size)
                logLn = "step %d, training PSNR: %g" % (i, PSNR)
                print(logLn)
                logFile.write(logLn+'\n')
                logFile.flush()
                save_path = saver.save(sess, './model.ckpt')
                rd_idx = img_data.train.batch_idx
                f.write(str(rd_idx)+'\n')
                f.flush()


            sess.run(train_step, feed_dict={features: batch[0], ref_img: batch[1] })
            i += 1

        res = sess.run(SSE_res, feed_dict={features: img_data.test.images[:100], 
                        ref_img: img_data.test.labels[:100]})

        PSNR = psnr(res/_size)
    
        logLn = "Epoch %d, Test PSNR: %g" % (niter, PSNR)
        print(logLn)
        logFile.write(logLn+'\n') 
        logFile.flush()
        rd_idx =0 
        f.write(str(rd_idx))
        f.flush()

        save_path = saver.save(sess, './model.ckpt')
    
    rd_idx =0
    f.write(str(rd_idx))
    f.close()
    logFile.close()

    end_time =  datetime.datetime.now()
    spend_time = end_time - start_time
    print('Processing time: %s'%str(spend_time))

    return PSNR


def showResult(resImg):
    """ Display YCbCr image whose type is numpy array """
    img = resImg.astype('uint8')
    img = Image.fromarray(img, mode='YCbCr')
    img.show("Result")


def psnr(mse):
    """
    input: mean square error
    return: PSNR """
    return 10.*math.log10(1./mse)


def calcPSNR(img1, img2):
    """ calc psnr of (img1-img2)"""

    mse= np.sum((img1.astype('float') - img2.astype('float'))**2)
    mse /= float(img1.shape[0] * img1.shape[1])

    return 10.*math.log10(255.*255./mse)


def test_main():
    """ """

    numLayer = 20

    fn = 'model.txt'
    f = open(fn, 'r')
    dat = f.readlines()

    NN= genCNNParameter(dat)

    img_fn = 'baby_GT.bmp'
    im = blurAndNormalize(img_fn)

    result = testModel(NN, im, numLayer)

    resImg = result[0, :, :, 0]*255
    resImg = np.clip(resImg,0,255)

    Y, Cb, Cr = getYCbCr(img_fn)
    colorImg = np.ndarray((Y.shape[0], Y.shape[1], 3),dtype="uint8")
    colorImg[:,:,0]=resImg
    colorImg[:,:,1]=Cb
    colorImg[:,:,2]=Cr

    print( 'PSNR of NN: ',    calcPSNR(Y, resImg), 'dB')
    print( 'PSNR of Bicubic', calcPSNR(Y, im*255), 'dB')

    showResult(colorImg)


def train_main( im=None ):

    nnLayer = setCNNParameter()

    if im is not None:

        pseudoH5 = dict() 
        pseudoH5['data'] = [im]
        pseudoH5['label'] = [im]


        iData = imgData(pseudoH5, pseudoH5)
        imgShape = im.shape
        
        return trainModel(nnLayer, iData, imgShape, isTest=True)

    train_h5 = h5py.File("train.h5", "r")
    test_h5  = h5py.File("test.h5", "r")

    #Data preparation
    iData = imgData(test_h5, train_h5)
    imgShape = (41,41)
        
    psnr = trainModel(nnLayer, iData, imgShape, isTest=False)

    #print("Test PSNR %g"%psnr)


if __name__ == '__main__':
    import sys

    if len(sys.argv) <2:
        print('Wrong parameter')
        print('Ex) For test, Type python test.py test')
        print('Ex) For test, Type python test.py t2 image.bmp')
        print('Ex) For train, Type python test.py test')

    
    if sys.argv[1] == 'test':
        test_main()
        
    elif sys.argv[1] == 'train':
        train_main()

    elif sys.argv[1] == 't2':
        if len(sys.argv) <3:
            print('Wrong parameter')
            print('Ex) For test, Type python test.py test')

        #img_fn = 'baby_GT.bmp'
        img_fn = sys.argv[2]
        Y, Cb, Cr = getYCbCr(img_fn)
        blurImg = getBlur(Y)

        result = train_main(blurImg/255.)

        #print result.shape

        resImg = result[0, :, :, 0]*255
        resImg = np.clip(resImg,0,255)

        #Y, Cb, Cr = getYCbCr(img_fn)
        colorImg = np.ndarray((resImg.shape[0], resImg.shape[1], 3),dtype="uint8")
        colorImg[:,:,0]= resImg
        colorImg[:,:,1]= Cb
        colorImg[:,:,2]= Cr

        print( 'PSNR of NN: ',      calcPSNR(Y, resImg), 'dB')
        print( 'PSNR of Bicubic: ', calcPSNR(Y, blurImg), 'dB')

        showResult(colorImg)


    else:
        print('Wrong parameter')
        print('Ex) For test,\n Type python test.py test') 
        print('Ex) For train,\n Type python test.py test') 
